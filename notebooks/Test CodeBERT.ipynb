{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8276324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhijit\\documents\\github\\yhack-mini\\notebooks\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neulab/codebert-python\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"neulab/codebert-python\")\n",
    "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a2cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.875249445438385, 'token': 8, 'token_str': ' and', 'sequence': 'if (x is not None) and (x > 0)'}\n",
      "{'score': 0.017183667048811913, 'token': 50, 'token_str': ' or', 'sequence': 'if (x is not None) or (x > 0)'}\n",
      "{'score': 0.013177888467907906, 'token': 463, 'token_str': 'and', 'sequence': 'if (x is not None)and (x > 0)'}\n",
      "{'score': 0.012697670608758926, 'token': 671, 'token_str': ' return', 'sequence': 'if (x is not None) return (x > 0)'}\n",
      "{'score': 0.010224265046417713, 'token': 48200, 'token_str': ' &&', 'sequence': 'if (x is not None) && (x > 0)'}\n"
     ]
    }
   ],
   "source": [
    "outputs = fill_mask(\"if (x is not None) <mask> (x > 0)\")\n",
    "for output in outputs:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83439bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9669309854507446, 'token': 16, 'token_str': ' is', 'sequence': '<s>if var1 is<mask> None:</s>'}\n",
      "{'score': 0.00770614156499505, 'token': 328, 'token_str': '!', 'sequence': '<s>if var1!<mask> None:</s>'}\n",
      "{'score': 0.002733553759753704, 'token': 28696, 'token_str': ' <', 'sequence': '<s>if var1 <<mask> None:</s>'}\n",
      "{'score': 0.002088442211970687, 'token': 50118, 'token_str': '\\n', 'sequence': '<s>if var1\\n<mask> None:</s>'}\n",
      "{'score': 0.0018904786556959152, 'token': 35, 'token_str': ':', 'sequence': '<s>if var1:<mask> None:</s>'}\n",
      "\n",
      "{'score': 0.9925784468650818, 'token': 45, 'token_str': ' not', 'sequence': '<s>if var1<mask> not None:</s>'}\n",
      "{'score': 0.001338448142632842, 'token': 5214, 'token_str': '=', 'sequence': '<s>if var1<mask>= None:</s>'}\n",
      "{'score': 0.0013240614207461476, 'token': 16, 'token_str': ' is', 'sequence': '<s>if var1<mask> is None:</s>'}\n",
      "{'score': 0.0009433833765797317, 'token': 49333, 'token_str': '!=', 'sequence': '<s>if var1<mask>!= None:</s>'}\n",
      "{'score': 0.0006681906525045633, 'token': 45994, 'token_str': ' ==', 'sequence': '<s>if var1<mask> == None:</s>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = fill_mask(\"if var1 <mask> <mask> None:\")\n",
    "for output in outputs:\n",
    "    for sub_output in output:\n",
    "        print(sub_output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27dd0587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.1390775889158249, 'token': 17265, 'token_str': 'print', 'sequence': 'print ( x )'}\n",
      "{'score': 0.09198562055826187, 'token': 5780, 'token_str': ' print', 'sequence': ' print ( x )'}\n",
      "{'score': 0.03168381378054619, 'token': 41975, 'token_str': 'import', 'sequence': 'import ( x )'}\n",
      "{'score': 0.01466455589979887, 'token': 1423, 'token_str': ' y', 'sequence': ' y ( x )'}\n",
      "{'score': 0.013982338830828667, 'token': 37131, 'token_str': ' eval', 'sequence': ' eval ( x )'}\n"
     ]
    }
   ],
   "source": [
    "outputs = fill_mask(\"<mask> ( x )\")\n",
    "for output in outputs:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7508d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tokenize import generate_tokens\n",
    "\n",
    "def get_best_output(outputs):\n",
    "    probs = defaultdict(float)\n",
    "    for output in outputs:\n",
    "        probs[output[\"token_str\"].strip()] += output[\"score\"]\n",
    "    return max(probs.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08ae37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if ( x is not None ) or ( x > 0 ) :\n",
      "CHANGE { or } to { and }\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "text = \"\"\"if (x is not None) or (x > 0):\n",
    "    return x\n",
    "\"\"\"\n",
    "\n",
    "line = 0  # center of attention\n",
    "lines = [x + \"\\n\" for x in text.split(\"\\n\")]\n",
    "N = len(lines)\n",
    "\n",
    "tokens = list(generate_tokens(lambda L=iter(lines): next(L)))\n",
    "filtered_tokens = defaultdict(list)\n",
    "for token in tokens:\n",
    "    filtered_tokens[token.start[0] - 1].append(token)\n",
    "line_lengths = [filtered_tokens[i][-1].end[1] for i in range(N)]\n",
    "cumulative_lengths = [sum(line_lengths[:i]) for i in range(N)]\n",
    "   \n",
    "curr_tokens = filtered_tokens[line]\n",
    "curr_token_strings = [x.string for x in curr_tokens]\n",
    "print(\" \".join(curr_token_strings).strip())\n",
    "\n",
    "suggestions = []\n",
    "for i in range(len(curr_tokens)):\n",
    "    prev = curr_token_strings[i]\n",
    "    curr_token_strings[i] = \"<mask>\"\n",
    "    string = \" \".join(curr_token_strings).strip()\n",
    "    curr_token_strings[i] = prev\n",
    "    outputs = fill_mask(string)\n",
    "    best_output, best_prob = get_best_output(outputs)\n",
    "    if best_output.strip() != prev.strip() and best_prob > 0.8:\n",
    "        print(\"CHANGE {\", prev, \"} to {\", best_output, \"}\")\n",
    "        start = cumulative_lengths[curr_tokens[i].start[0] - 1] + curr_tokens[i].start[1]\n",
    "        end = cumulative_lengths[curr_tokens[i].end[0] - 1] + curr_tokens[i].end[1]\n",
    "        suggestions.append(((prev, start, end), best_output))\n",
    "        \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e0ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
